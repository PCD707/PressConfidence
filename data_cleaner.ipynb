{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9c36999-7808-4ddd-b901-70f08bacaebe",
   "metadata": {},
   "source": [
    "The analysis began with the use of Microsoft Excel tools, specifically [Power Query](https://learn.microsoft.com/en-us/power-query/power-query-what-is-power-query) and [Power Pivot](https://support.microsoft.com/en-us/office/power-pivot-overview-and-learning-f9001958-7901-4caa-ad80-028a6d2432ed), to inspect, merge, and clean the dataset. I standardized formatting and naming conventions, addressing inconsistencies in country names, and added columns to facilitate demographic analysis, including Age Groups, Generations, Regions, and Sub-Regions. The five regions in this article are made up of the following sub-regions:\n",
    "•\tAfrica – Northern, Western, Eastern, Southern, and Central\n",
    "•\tAmericas – North, South, Central, the Caribbean\n",
    "•\tAsia – North, East, Southeast, South, Central, and West\n",
    "•\tEurope – Northern, Southern, Eastern, Western\n",
    "•\tOceania – Australasia, Melanesia, Micronesia, and Polynesia\n",
    "\n",
    "Subsequently, I transitioned to [Python](https://en.wikipedia.org/wiki/Python_(programming_language)) (Version 3.12) and [Jupyter Notebook](https://www.geeksforgeeks.org/data-science/jupyter-notebook/) for interactive data analysis. To visualise the data, I employed [Plotly](https://plotly.com/python/), an open-source graphing library that allows for the embedding of .html style figures. Additional Python packages used:\n",
    "-\tPandas: For data manipulation and analysis\n",
    "-\tNumpy: For numerical operations and handling arrays\n",
    "-\tos: For file and directory manipulation, to interact with the operating system\n",
    "-\tOrderedDict from Collections: Specialised dictionary with order preservation. Useful when order of items is important\n",
    "-\tMath: For complex mathematical calculations without building them from scratch\n",
    "\n",
    "I converted the dataset from .xlsx (Excel) to .csv (Comma Separated Value) format and performed the following, additional, cleaning steps:\n",
    "-\tFiltered out invalid values while retaining relevant data.\n",
    "-\tReversed the WVS/EVS confidence scale, so that instead of 1 = highest confidence and 4 = lowest confidence it is now vice versa such that 1 = lowest confidence and 4 = highest confidence \n",
    "\n",
    "Finally, most of my functions implement Pandas’ pivot tables which helps summarise and aggregate data from my dataset. This allowed me to group data by specific columns (i.e., Age Groups) and perform calculations such as the mean or median (etc.) on grouped data. Main functions are found in plot_functions.ipynb.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b7a2536-4be0-4f80-8ee5-163e2f509d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def clean_data(df):\n",
    "    \"\"\"\n",
    "    Cleans and normalizes WVS/EVS survey data.\n",
    "    - Preserves valid data across all columns without dropping entire rows.\n",
    "    - Filters invalid values column-wise using .where()\n",
    "    - Applies reverse scale to confidence-related variables + nationalpride.\n",
    "    Returns cleaned DataFrame and list of confidence columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Ordered Categories ---\n",
    "    wave_order = [\"1981-'84\", \"1990-'94\", \"1995-'98\", \"1999-'04\", \"2005-'09\", \"2010-'14\", \"2017-'22\"]\n",
    "    age_order = [\"Teen (<18)\", \"Young Adult (18-30)\", \"Middle Adult (31-45)\",\n",
    "                 \"Older Adult (46-65)\", \"Elder Adult (66+)\"]\n",
    "    gen_order = [\"Lost Generation (1883-'00)\", \"Greatest Generation (1901-'27)\", \"Silent Generation (1928-'45)\",\n",
    "                 \"Baby Boomer (1946-'64)\", \"Gen X (1965-'80)\", \"Millennial (1981-'96)\", \"Gen Z (1997-'12)\",\n",
    "                 \"DNK(-1)\", \"NO ANS(-2)\", \"N/A(-3)\", \"Not in EVS(-4)\", \"MISSING(-5)\"]\n",
    "    \n",
    "\n",
    "    # --- Valid Ranges ---\n",
    "    valid_sex = [\"Male\", \"Female\"]\n",
    "    valid_born = [\"Yes\", \"No\"]\n",
    "    valid_confidence = [-1, -2, 1, 2, 3, 4]\n",
    "    valid_politicalself = [-1, -2, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "    valid_govself = [-1, -2, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "    valid_pride = [-1, -2, 1, 2, 3, 4]\n",
    "    valid_generations = gen_order[:7]\n",
    "\n",
    "    confidence_columns = [\n",
    "        'Press_Confidence', 'Police_Confidence', 'Government_Confidence',\n",
    "        'PolParties_Confidence', 'EU_Confidence', 'UN_Confidence'\n",
    "    ]\n",
    "\n",
    "    \n",
    "\n",
    "    # --- Normalize Sex and BornHere codes (stored as strings in your CSV)\n",
    "    df['Sex'] = df['Sex'].replace({'1': 'Male', '2': 'Female'})\n",
    "    df['BornHere'] = df['BornHere'].replace({'0': 'No', '1': 'Yes'})\n",
    "\n",
    "    # --- Set ordered categorical types\n",
    "    df['Years'] = pd.Categorical(df['Years'], categories=wave_order, ordered=True)\n",
    "    df['Age Group'] = pd.Categorical(df['Age Group'], categories=age_order, ordered=True)\n",
    "    df['Generation'] = pd.Categorical(df['Generation'], categories=gen_order, ordered=True)\n",
    "\n",
    "    \n",
    "\n",
    "    # --- Filter invalid values column-wise (preserve rows, just set invalid cells to NaN)\n",
    "    df['Sex'] = df['Sex'].where(df['Sex'].isin(valid_sex))\n",
    "    df['BornHere'] = df['BornHere'].where(df['BornHere'].isin(valid_born))\n",
    "    df['Generation'] = df['Generation'].where(df['Generation'].isin(valid_generations))\n",
    "    df['PoliticalSelfRating'] = df['PoliticalSelfRating'].where(df['PoliticalSelfRating'].isin(valid_politicalself))\n",
    "    df['GovVsSelf'] = df['GovVsSelf'].where(df['GovVsSelf'].isin(valid_govself))\n",
    "    df['NationalPride'] = df['NationalPride'].where(df['NationalPride'].isin(valid_pride))\n",
    "\n",
    "     \n",
    "    \n",
    "    # --- Convert confidence columns to numeric (if not already)\n",
    "    df[confidence_columns] = df[confidence_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # --- Filter invalid confidence scores\n",
    "    df[confidence_columns] = df[confidence_columns].apply(\n",
    "        lambda col: col.where(col.isin(valid_confidence))\n",
    "    )\n",
    "\n",
    "    \n",
    "\n",
    "    # --- Reverse scale for confidence values + NationalPride\n",
    "    reverse_scale = {1: 4, 2: 3, 3: 2, 4: 1}\n",
    "    df[confidence_columns + ['NationalPride']] = df[confidence_columns + ['NationalPride']].replace(reverse_scale)\n",
    "\n",
    "    \n",
    "\n",
    "    return df, confidence_columns\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
